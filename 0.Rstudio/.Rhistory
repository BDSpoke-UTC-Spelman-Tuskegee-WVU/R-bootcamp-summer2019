#square
3^2
5-2
5/2
5*3
#Q: 5 to the 3rd power?
5^3
# * means times
5*5*5
#natural log, No 'ln'
log10(100)
#exponetial function
exp(pi)
exp(0)
#square-root
sqrt(pi)
sqrt(100)
#Q, 100 to the 1/2 power
100^0.5
#these are arrays (vectors)
#x = seq(0,10, 0.1)
#x;
x <- 5:9;  # = means assignment, x will stay in memory
x;
1:15 #no assignment, no results stay in memory
z <- 1:15;
x[1]
x = 3:10
x
length(x)  #length() is an function in R
#Q what does length() do?
help(length)
?length
?seq
help(seq)
?length
x = 3:10
x+1 #no assignment
x = x * 2; # what happens to x?
#The difference bw theese two lines is an important computing concept
# x =x+1, assign a new value from righthandside to the lefthandside.
x;
y = x+4
#simple plot
plot( y ~ x, main= "y ~ x" );
#plot( x ~ y, main= "x~y" )
y = x+4
#simple plot
plot( y ~ x, main= "y ~ x" );
plot( x ~ y, main= "x~y" )
x = 1:10;
y = x;
plot( y ~ x, pch=x);
x = 1:30;
y = x;
plot( y ~ x, pch=x);
tb = read_excel('gisaid_monthly_submissions_global_2021-05-12-0958.xlsx')
rm( list=ls()) #clean up worksapce
library(tidyverse)
library(lubridate)
library(readxl)
tb = read_excel('gisaid_monthly_submissions_global_2021-05-12-0958.xlsx')
rm( list=ls()) #clean up worksapce
library(tidyverse)
library(lubridate)
library(readxl)
rm( list=ls()) #clean up worksapce
library(tidyverse)
library(lubridate)
library(readxl)
rm( list=ls()) #clean up worksapce
library(tidyverse)
library(lubridate)
library(readxl)
tb = read_excel('gisaid_monthly_submissions_global_2021-05-12-0958.xlsx')
View(tb)
str(tb)
#indexing features of R
tb[1:5, 2:3]
#what does mean?
#tb$age[?] #try for 5th row in age
# what is the 5th and 9th rows in age and SciLitScore:
tb[c(5,9), c(7,2)]
#indexing features of R
tb[1:5, 2:3]
#indexing features of R
tb[1:5, 2:4]
tb[3, 3]
tb[3, 4]
# what is the 5th and 9th rows in age and SciLitScore:
tb[c(3, 4, 7), c(4,5)]
tb[c(3,4), c( '03/2020', "08/2020")]
tb[c(3,4), c( '03/2020', "04/2020")]
tail(tb)
tb[,2]
tb$`01/2020`
tb1 = t(tb[, 2: length(tb[1,])])
tb1 = data.frame(tb1)
names(tb1) = t(tb[,1]) #use contry names as columns names in tb1
tail(tb1)
rm( list=ls()) #clean up worksapce
library(tidyverse)
library(lubridate)
library(readxl)
tb = read_excel('gisaid_monthly_submissions_global_2021-05-12-0958.xlsx')
str(tb)
?str
help(str);
head(tb)
#indexing features of R
tb[1:5, 2:4]
tb[3, 4]
# what is the 5th and 9th rows in age and SciLitScore:
tb[c(3, 4, 7), c(4,5)]
tb[c(3,4), c( '03/2020', "04/2020")]
tail(tb)
head( tb[, 2:3], n=2)
# how many columns?
length(tb[1,])
print(paste( "There are ", length(tb[1,]), " columns"))
tb$`01/2020`
tb1 = t(tb[, 2: length(tb[1,])])
tb1 = data.frame(tb1)
names(tb1) = t(tb[,1]) #use contry names as columns names in tb1
tail(tb1)
library(zoo)
tb1$date = as.yearmon( row.names(tb1),  "%m/%Y")
ggplot( tb1, aes(x=date, y=USA)) + geom_point()
names(tb1)
tb1$USA
tb1 %>% select (USA)
tb1 %>% filter( USA > 1) %>% select (USA, China)
head(tb1)
tb1$"monthly total:"
sum(tb1$"monthly total:") / 1E6
head(tb[, 2: length(tb[1,])]))
tb[1:5, 2: length(tb[1,])]
t ( tb[1:5, 2: length(tb[1,])] )
tb1 = t ( tb[1:5, 2: length(tb[1,])] )
#tb1 = t(tb[, 2: length(tb[1,])])
tb1 = data.frame(tb1)
names(tb1) = t(tb[,1]) #use contry names as columns names in tb1
tb1 = t(tb[, 2: length(tb[1,])])
tb1 = data.frame(tb1)
names(tb1) = t(tb[,1]) #use contry names as columns names in tb1
head(tb1)
library(zoo)
tb1$date = as.yearmon( row.names(tb1),  "%m/%Y")
ggplot( tb1, aes(x=date, y=USA)) + geom_point()
tb1$date = as.yearmon( row.names(tb1),  "%m/%Y")
ggplot( tb1, aes(x=date, y=USA)) + geom_point()
tb1$date = as.yearmon( row.names(tb1),  "%m/%Y")
ggplot( tb1, aes(x=date, y=USA))
#+ geom_point()
tb1$date = as.yearmon( row.names(tb1),  "%m/%Y")
ggplot( tb1, aes(x=date, y=USA)) + geom_point()
names(tb1)
tb1$USA
tb1 %>% select (USA)
tb1 %>% filter( USA > 100) %>% select (USA, China)
tb1 %>% filter( USA > 100) %>% select (USA, China)
tb1[, c("USA", "China")]
tb1 %>% filter( USA > 100 & USA < 1000 ) %>% select (USA, China)
tb1[, c("USA", "China")]
tb1 %>% filter( USA > 100 & USA < 5000 ) %>% select (USA, China)
tb1[, c("USA", "China")]
sum(tb1$"monthly total:") / 1E6
tb1$"monthly total:"
tb1$USA_percentage = tb1$USA / tb1$"monthly total:"
tb1$USA_percentage = tb1$USA / tb1$"monthly total:"
tb1$USA_percentage
sum(tb1$"monthly total:")
sum(tb1$"monthly total:") / 1E6
rm( list=ls()) #clean up worksapce
library(tidyverse)
library(lubridate)
library(reshape2)
library(ggplot2)
library(dplyr)
# load JHU covid19 data set with tidyverse read_csv
# this is the URL for "view raw " for csv files on GitHub
tb = read_csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv")
?str
help(str);
str(tb[ , 1:10]);
#indexing features of R
tb[1:5, 2:3]
tb$age #what does mean?
#tb$age[?] #try for 5th row in age
# what is the 5th and 9th rows in age and SciLitScore:
tb[c(5,9), c(7,2)]
tb[c(5,9), c('FIPS', 'Admin2', "Province_State")]
head(tb)
head( tb[, 2:3], n=2)
# how many columns?
length(tb[1,])
print(paste( "There are ", length(tb[1,]), " columns"))
#tb %>% select( 12:length(tb[1,]) )
tb1 <- tb %>% dplyr::select(12:length(tb[1,])) %>% as.matrix()
tb1 = as.data.frame(t(tb1)) # t for transpose, then convert to a dataframe
tail(tb1)
names(tb1) = tb$Combined_Key
#tail(tb1[100:110,1:10])
tail(tb1[,1:10])
library(lubridate)
mdy("10/1/2020")
current_dates = names(tb)[12:length(tb[1,])]
class(current_dates)
current_dates
mdy(current_dates[1:10])
tb1$dates = mdy(current_dates)
tail(tb1)
## Select a time window (row window) using 'filter'
tb1 %>% filter( dates > mdy("4/30/2020"), dates < mdy("5/31/20")) %>% head()
start = mdy("12/1520")
end = start + ddays(30)
tb1 %>% dplyr::filter( dates >= start, dates <=  end)  %>% dplyr::select(1:5)
tb_sub <-
tb1 %>% dplyr::filter( dates >= start, dates <  start + ddays(30)) %>% dplyr::select( c(1:5), dates)
tb_sub
ggplot(tb_sub, aes( x = dates, y=tb_sub[,3])) + geom_point() + geom_smooth()
mycounties = c( 'Macon, Alabama, US') #Change here to your home county and state
#mycounties = c( 'San Francisco, California, US') #Change here to your home county and state
#mycounties = c( 'Santa Clara, California, US') #Change here to your home county and state
#mycounties = c('Hennepin, Minnesota, US') #Minneapolis
#mycounties = c('Harris, Texas, US') #Houston
#mycounties = c('Cobb, Georgia, US') #Houston
#mycounties = c( 'Hamilton, Tennessee, US') #Change here to your home county and state
tb = read_csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv")
tb1 <- tb %>% dplyr::select(12:length(tb[1,])) %>% as.matrix()
tb1 = as.data.frame(t(tb1))
names(tb1) = tb$Combined_Key
current_dates = names(tb)[12:length(tb[1,])]
tb1$dates = mdy(current_dates)
#head(tb1)
days_window = 340  # time  window
endday = today(tzone ='EST')
tb_sub <- tb1 %>%
dplyr::select( all_of(mycounties), 'dates') %>%
dplyr::filter( between(dates, endday-ddays(days_window), endday))
head(tb_sub)
tb_sub[,1]
diff( tb_sub[,1])
local_dailycases = c(0, diff( tb_sub[,1] )) # we add zero to the first day
tb_daily_sub = data.frame( local_dailycases )
head(tb_daily_sub)
tb_daily_sub$YMD = mdy(row.names(tb_sub))
head(tb_daily_sub)
row.names(tb_daily_sub) = tb_daily_sub$YMD #add row names
tail(tb_daily_sub )
names(tb_daily_sub)[1] = mycounties #add column names
tail(tb_daily_sub)
myplot <- ggplot(tb_daily_sub, aes(x=YMD, y=tb_daily_sub[,1]))
myplot + geom_point() + stat_smooth(span=0.3)
# Download the Google Mobility data
url =  "https://www.gstatic.com/covid19/mobility/Region_Mobility_Report_CSVs.zip"
download.file( url, destfile = "download/google.zip")
# You would need to unzip the downloaded zip file
# If you use RStudio-Cloud, these file may be in your workspace
tbGMUS20 = read_csv("download/google/2020_US_Region_Mobility_Report.csv")
tail(tbGMUS20)
tbGMUS21 = read_csv("download/google/2021_US_Region_Mobility_Report.csv")
tail(tbGMUS21)
tbGMUS = rbind( tbGMUS20, tbGMUS21)
myState = 'Alabama'
myCounty = "Macon County" #Google location is different from JHU
tbGMmycounty <-
tbGMUS %>% filter( sub_region_1 == myState, sub_region_2 == myCounty)
head(tbGMmycounty)
max(tbGMmycounty$date) #the most recent date of the mobility report
head( tb_daily_sub)
tb_daily_mycounty = tb_daily_sub
names(tb_daily_mycounty) = c("DailyCases", "date")
tail(tb_daily_mycounty)
tb_GMCovidmycounty = merge(x=tb_daily_mycounty, y=tbGMmycounty, by= 'date', all.y=FALSE)
row.names(  tb_GMCovidmycounty ) =  tb_GMCovidmycounty$date
tail( tb_GMCovidmycounty )
names(tb_GMCovidmycounty  )
#names(tb_GMCovidmycounty  )[10:12]
print( paste( "There are ", length(tb_GMCovidmycounty[1,]), "columns"))
tb_GMCovidmycounty2  <- tb_GMCovidmycounty  %>% dplyr::select(2, 11:16 ) # select values columns
tail(tb_GMCovidmycounty2 )
tb_GMCovidmycounty_scaled <-  data.frame( scale(tb_GMCovidmycounty2) )
head( tb_GMCovidmycounty_scaled  )
# add the date column back
tb_GMCovidmycounty_scaled$date = ymd(row.names(tb_GMCovidmycounty_scaled))
tail( tb_GMCovidmycounty_scaled  )
names( tb_GMCovidmycounty_scaled )
selected_columns = c('DailyCases', "transit_stations_percent_change_from_baseline", 'workplaces_percent_change_from_baseline','residential_percent_change_from_baseline')
df_melt <- melt(tb_GMCovidmycounty_scaled, measure.vars=selected_columns, value.names="Values", varialbe.name="varialbe" )
plot <- ggplot(df_melt, aes(x=date, y=value, color=variable)) + stat_smooth(span=0.15)
plot + ggtitle( paste( myCounty, myState))
rm( list=ls()) #clean up worksapce
library(tidyverse)
library(lubridate)
library(reshape2)
library(ggplot2)
library(dplyr)
# load JHU covid19 data set with tidyverse read_csv
# this is the URL for "view raw " for csv files on GitHub
tb = read_csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv")
View(tb)
# how many columns?
length(tb[1,])
print(paste( "There are ", length(tb[1,]), " columns"))
#tb %>% select( 12:length(tb[1,]) )
tb1 <- tb %>% dplyr::select(12:length(tb[1,])) %>% as.matrix()
tb1 = as.data.frame(t(tb1)) # t for transpose, then convert to a dataframe
tail(tb1)
View(tb1)
names(tb1) = tb$Combined_Key
#tail(tb1[100:110,1:10])
tail(tb1[,1:10])
library(lubridate)
mdy("10/1/2020")
library(lubridate)
mdy("10/1/2020")
current_dates = names(tb)[12:length(tb[1,])]
class(current_dates)
current_dates
mdy(current_dates[1:10])
tb1$dates = mdy(current_dates)
tail(tb1)
View(tb1)
## Select a time window (row window) using 'filter'
tb1 %>% filter( dates > mdy("4/30/2020"), dates < mdy("5/31/20")) %>% head()
## Select a time window (row window) using 'filter'
tb1 %>% filter( dates > mdy("3/30/2021"), dates < mdy("5/16/20")) %>% head()
## Select a time window (row window) using 'filter'
tb1 %>% filter( dates > mdy("3/30/2021"), dates < mdy("5/16/21")) %>% head()
## Select a time window (row window) using 'filter'
tb1 %>% filter( dates > mdy("3/30/2020"), dates < mdy("5/16/20")) %>% head()
View(tb1)
View(tb1)
View(tb1)
View(tb1)
start = mdy("12/15/20")
end = start + ddays(30)
tb1 %>% dplyr::filter( dates >= start, dates <=  end)  %>% dplyr::select(1:5)
tb_sub <-
tb1 %>% dplyr::filter( dates >= start, dates <  start + ddays(30)) %>% dplyr::select( c(1:5), dates)
head(tb_sub)
ggplot(tb_sub, aes( x = dates, y=tb_sub[,3])) + geom_point() + geom_smooth()
mycounties = c( 'Macon, Alabama, US') #Change here to your home county and state
#mycounties = c( 'San Francisco, California, US') #Change here to your home county and state
#mycounties = c( 'Santa Clara, California, US') #Change here to your home county and state
#mycounties = c('Hennepin, Minnesota, US') #Minneapolis
#mycounties = c('Harris, Texas, US') #Houston
#mycounties = c('Cobb, Georgia, US') #Houston
#mycounties = c( 'Hamilton, Tennessee, US') #Change here to your home county and state
tb = read_csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv")
tb1 <- tb %>% dplyr::select(12:length(tb[1,])) %>% as.matrix()
tb1 = as.data.frame(t(tb1))
names(tb1) = tb$Combined_Key
current_dates = names(tb)[12:length(tb[1,])]
tb1$dates = mdy(current_dates)
#head(tb1)
days_window = 340  # time  window
endday = today(tzone ='EST')
tb_sub <- tb1 %>%
dplyr::select( all_of(mycounties), 'dates') %>%
dplyr::filter( between(dates, endday-ddays(days_window), endday))
head(tb_sub)
View(tb_sub)
tb_sub[,1]
local_dailycases = c(0, diff( tb_sub[,1] )) # we add zero to the first day
tb_daily_sub = data.frame( local_dailycases )
head(tb_daily_sub)
tb_daily_sub$YMD = mdy(row.names(tb_sub))
head(tb_daily_sub)
row.names(tb_daily_sub) = tb_daily_sub$YMD #add row names
tail(tb_daily_sub )
View(tb_daily_sub)
names(tb_daily_sub)[1] = mycounties #add column names
tail(tb_daily_sub)
myplot <- ggplot(tb_daily_sub, aes(x=YMD, y=tb_daily_sub[,1]))
myplot + geom_point() + stat_smooth(span=0.3)
# If you use RStudio-Cloud, these file may be in your workspace
tbGMUS20 = read_csv("download/google/2020_US_Region_Mobility_Report.csv")
tail(tbGMUS20)
# If you use RStudio-Cloud, these file may be in your workspace
tbGMUS20 = read_csv("download/google/2020_US_Region_Mobility_Report.csv")
tail(tbGMUS20)
?rbind
tbGMUS = rbind( tbGMUS20, tbGMUS21)
tbGMUS21 = read_csv("download/google/2021_US_Region_Mobility_Report.csv")
tail(tbGMUS21)
tbGMUS = rbind( tbGMUS20, tbGMUS21)
View(tbGMUS)
View(tbGMUS20)
View(tbGMUS)
myState = 'Alabama'
myCounty = "Macon County" #Google location is different from JHU
tbGMmycounty <-
tbGMUS %>% filter( sub_region_1 == myState, sub_region_2 == myCounty)
head(tbGMmycounty)
max(tbGMmycounty$date) #the most recent date of the mobility report
head( tb_daily_sub)
tb_daily_mycounty = tb_daily_sub
names(tb_daily_mycounty) = c("DailyCases", "date")
tail(tb_daily_mycounty)
head( tb_daily_sub)
tb_daily_mycounty = tb_daily_sub
names(tb_daily_mycounty) = c("DailyCases", "date")
tail(tb_daily_mycounty)
View(tb_daily_mycounty)
View(tbGMmycounty)
?merge
tb_GMCovidmycounty = merge(x=tb_daily_mycounty, y=tbGMmycounty, by= 'date', all.y=FALSE)
row.names(  tb_GMCovidmycounty ) =  tb_GMCovidmycounty$date
tail( tb_GMCovidmycounty )
names(tb_GMCovidmycounty  )
#names(tb_GMCovidmycounty  )[10:12]
View(tb_GMCovidmycounty)
print( paste( "There are ", length(tb_GMCovidmycounty[1,]), "columns"))
tb_GMCovidmycounty2  <- tb_GMCovidmycounty  %>% dplyr::select(2, 11:16 ) # select values columns
tail(tb_GMCovidmycounty2 )
tail(tb_GMCovidmycounty2 )
?scale
tb_GMCovidmycounty_scaled <-  data.frame( scale(tb_GMCovidmycounty2) )
head( tb_GMCovidmycounty_scaled  )
head( tb_GMCovidmycounty_scaled  )
tb_GMCovidmycounty2  <- tb_GMCovidmycounty  %>% dplyr::select(2, 11:16 ) # select values columns
tail(tb_GMCovidmycounty2 )
tb_GMCovidmycounty_scaled <-  data.frame( scale(tb_GMCovidmycounty2) )
head( tb_GMCovidmycounty_scaled  )
# add the date column back
tb_GMCovidmycounty_scaled$date = ymd(row.names(tb_GMCovidmycounty_scaled))
tail( tb_GMCovidmycounty_scaled  )
summary(tb_GMCovidmycounty_scaled )
selected_columns = c('DailyCases', "transit_stations_percent_change_from_baseline", 'workplaces_percent_change_from_baseline')
df_melt <- melt( tb_GMCovidmycounty_scaled, measure.vars=selected_columns, value.names="Values", varialbe.name="varialbe" )
View(df_melt)
View(df_melt)
names( tb_GMCovidmycounty_scaled )
selected_columns = c('DailyCases', "transit_stations_percent_change_from_baseline", 'workplaces_percent_change_from_baseline')
df_melt <- melt( tb_GMCovidmycounty_scaled, measure.vars=selected_columns, value.names="Values", varialbe.name="varialbe" )
plot <- ggplot(df_melt, aes(x=date, y=value, color=variable)) + stat_smooth(span=0.15)
plot + ggtitle( paste( myCounty, myState))
names( tb_GMCovidmycounty_scaled )
selected_columns = c('DailyCases', "transit_stations_percent_change_from_baseline", 'workplaces_percent_change_from_baseline')
df_melt <- melt( tb_GMCovidmycounty_scaled, measure.vars=selected_columns, value.names="Values", varialbe.name="varialbe" )
plot <- ggplot(df_melt, aes(x=date, y=value, color=variable)) + stat_smooth(span=0.15)
plot + ggtitle( paste( myCounty, myState))
View(tb_daily_sub)
View(tb_daily_mycounty)
View(tb_GMCovidmycounty)
rm(list=ls()) #clearn my workspace
library(tidyverse)
Election20df = read_csv("https://raw.githubusercontent.com/tonmcg/US_County_Level_Election_Results_08-20/master/2020_US_County_Level_Presidential_Results.csv")
head(Election20df)
Election20df %>% select ( total_votes ) %>% sum()
sum( Election20df$total_votes )
Election20df %>% select ( votes_gop ) %>% sum()
Election20df %>% select ( votes_dem ) %>% sum()
mystate = "California"
Californiadf <-
Election20df %>% filter( state_name == mystate) %>%  arrange( per_point_diff)
names( Californiadf )[8] = "percentage_for_GOP"
ggplot(Californiadf, aes(percentage_for_GOP)) +  geom_histogram()
#summary(Californiadf$per_gop)
Statedf <- Election20df %>% select( state_name, votes_gop, votes_dem,  total_votes ) %>% group_by( state_name ) %>% summarise_if( is.numeric, sum)
Statedf$percentage_for_GOP = Statedf$votes_gop / Statedf$total_votes
ggplot(Statedf, aes(percentage_for_GOP)) +  geom_histogram()
Statedf %>% filter( percentage_for_GOP < 0.1 )
mean( Statedf$percentage_for_GOP)
quantile( Statedf$percentage_for_GOP )
groups =  cut( Statedf$percentage_for_GOP, c(0, 0.4, 0.47, 0.53, 0.5, 1) )
levels(groups) = c("deepblue", "blue", "swing", "red", "deepred")
Statedf$groups = groups
Censusdf = read_csv("https://raw.githubusercontent.com/hongqin/USA-census-county-level/main/USA-County-level-census-2010-2019.csv")
head(Censusdf)
Election20df$Location = paste( Election20df$county_name, Election20df$state_name, sep=", " )
Election20df$Location %in% Censusdf$Location
EleCen.df = merge( Election20df, Censusdf, by="Location")
Statedf2 <- EleCen.df %>% select( state_name, votes_gop, votes_dem,  total_votes, '2019' ) %>% group_by( state_name ) %>% summarise_if( is.numeric, sum)
head(Statedf2)
names( Statedf2)[5] = "population"
Statedf$population = Statedf2$population[match( Statedf$state_name , Statedf2$state_name ) ]
model1 = lm( Statedf$percentage_for_GOP ~ Statedf$population)
summary(model1)
model2 = lm(  Statedf$population ~ Statedf$groups)
summary(model2)
ggplot( Statedf, aes(x=groups, y=population)) + geom_point()
StateArea = read_csv("https://raw.githubusercontent.com/hongqin/data-USstates/master/state-areas.csv")
names( StateArea) = c("state_name", "area")
Statedf$area = StateArea$area[ match( Statedf$state_name  , StateArea$state_name ) ]
Statedf$pop_density = Statedf$population / Statedf$area
model = lm( Statedf$percentage_for_GOP ~ Statedf$pop_density)
summary(model)
ggplot( Statedf, aes(x=pop_density, y=percentage_for_GOP)) + geom_point()
Statedf3 <- Statedf %>% filter( percentage_for_GOP > 0.1)
ggplot( Statedf3, aes(x=pop_density, y=percentage_for_GOP)) +
geom_point() +
geom_smooth(method='lm')
ggplot( Statedf3, aes(x=groups, y=pop_density)) + geom_point()
ggplot( Statedf3, aes(x=groups, y=pop_density)) + geom_boxplot()
head(Statedf3)
Statedf3 %>% filter( groups == "deepred")
Statedf3 %>% filter( groups == "deepred") %>% select( pop_density)
deepred_pop_densities <-
Statedf3 %>% filter( groups == "deepred") %>% select( pop_density)
View(deepred_pop_densities)
deepred_pop_densities <-
Statedf3 %>% filter( groups == "deepred") %>% select( pop_density)
deepblue_pop_densities <-
Statedf3 %>% filter( groups == "deepblue") %>% select( pop_density)
deepred_pop_densities <-
Statedf3 %>% filter( groups == "deepred") %>% select( pop_density)
deepblue_pop_densities <-
Statedf3 %>% filter( groups == "deepblue") %>% select( pop_density)
t.test( deepblue_pop_densities, deepred_pop_densities, alternative = "greater")
