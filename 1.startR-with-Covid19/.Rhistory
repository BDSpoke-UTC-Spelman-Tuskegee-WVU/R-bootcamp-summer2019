#rename( tb1,   as.character( tb[,1] ) )
tb1 = t(tb[, 2: length(tb[1,])])
tb1 = data.frame(tb1)
names(tb1) = as.character(tb[,1])
#rename( tb1,   as.character( tb[,1] ) )
tb[,1]
str( tb[,1])
as.character(tb[,1])
tb1 = t(tb[, 2: length(tb[1,])])
tb1 = data.frame(tb1)
names(tb1) = t(tb[,1])
#rename( tb1,   as.character( tb[,1] ) )
tb1 = t(tb[, 2: length(tb[1,])])
tb1 = data.frame(tb1)
names(tb1) = t(tb[,1])
tail(tb1)
tb1$date = row.names(tb1)
tb1$date = row.names(tb1)
plot( tb1[, 1] ~ tb1$date)
tb1$date = row.names(tb1)
plot( tb1$Afghanistan ~ tb1$date)
tb1$date = row.names(tb1)
points( tb1$Argentina )
tb1$date = row.names(tb1)
plot( tb1$Argentina )
library(zoo)
as.monthyear
as.Date()
? as.Date
library(zoo)
tb1$date = as.yearmonth( row.names(tb1),  "%m/%Y")
library(zoo)
tb1$date = as.yearmon( row.names(tb1),  "%m/%Y")
plot( tb1$Argentina )
library(zoo)
tb1$date = as.yearmon( row.names(tb1),  "%m/%Y")
plot( tb1$Argentina  ~ tb1$date)
tb1$date
tail(tb1)
library(zoo)
tb1$date = as.yearmon( row.names(tb1),  "%m/%Y")
ggplot( tb1, asex=(x=date, y="USA"))
library(zoo)
tb1$date = as.yearmon( row.names(tb1),  "%m/%Y")
ggplot( tb1, aes(x=date, y="USA"))
library(zoo)
tb1$date = as.yearmon( row.names(tb1),  "%m/%Y")
ggplot( tb1, aes(x=date, y="USA")) + ggpoint()
library(zoo)
tb1$date = as.yearmon( row.names(tb1),  "%m/%Y")
ggplot( tb1, aes(x=date, y="USA")) + geom_point()
tb1 %>% select (USA)
library(zoo)
tb1$date = as.yearmon( row.names(tb1),  "%m/%Y")
ggplot( tb1, aes(x=date, y=USA)) + geom_point()
tb1 %>% select (USA)
tb1 %>% filtrer( USA > 1000) %>% select (USA)
tb1 %>% filter( USA > 1000) %>% select (USA)
tb1 %>% filter( USA > 1000) %>% select (USA, China)
tb1 %>% filter( USA > 10) %>% select (USA, China)
tb1 %>% filter( USA > 1) %>% select (USA, China)
tb1 %>% filter( USA > 1) %>% select (USA, China)
reticulate::repl_python()
x, y = 1, 2
reticulate::repl_python()
x, y = (1, 2)
reticulate::repl_python()
x = 1
reticulate::repl_python()
x = 1
reticulate::repl_python()
#x = 1
reticulate::repl_python()
#x = 1
rm( list=ls()) #clean up worksapce
library(tidyverse)
library(lubridate)
library(readxl)
tb = read_excel('gisaid_monthly_submissions_global_2021-05-12-0958.xlsx')
?str
help(str);
head(tb)
#indexing features of R
tb[1:5, 2:3]
tb$age #what does mean?
#tb$age[?] #try for 5th row in age
# what is the 5th and 9th rows in age and SciLitScore:
tb[c(5,9), c(7,2)]
tb[c(5,9), c( '01/2020', "08/2020")]
head(tb)
head( tb[, 2:3], n=2)
# how many columns?
length(tb[1,])
print(paste( "There are ", length(tb[1,]), " columns"))
tb1 = t(tb[, 2: length(tb[1,])])
tb1 = data.frame(tb1)
names(tb1) = t(tb[,1])
tail(tb1)
library(zoo)
tb1$date = as.yearmon( row.names(tb1),  "%m/%Y")
ggplot( tb1, aes(x=date, y=USA)) + geom_point()
tb1 %>% select (USA)
tb1 %>% filter( USA > 1) %>% select (USA, China)
rm( list=ls()) #clean up worksapce
library(tidyverse)
library(lubridate)
library(readxl)
tb = read_excel('gisaid_monthly_submissions_global_2021-05-12-0958.xlsx')
?str
help(str);
head(tb)
#indexing features of R
tb[1:5, 2:3]
tb$age #what does mean?
#tb$age[?] #try for 5th row in age
# what is the 5th and 9th rows in age and SciLitScore:
tb[c(5,9), c(7,2)]
tb[c(5,9), c( '01/2020', "08/2020")]
head(tb)
head( tb[, 2:3], n=2)
# how many columns?
length(tb[1,])
print(paste( "There are ", length(tb[1,]), " columns"))
tb1 = t(tb[, 2: length(tb[1,])])
tb1 = data.frame(tb1)
names(tb1) = t(tb[,1])
tail(tb1)
library(zoo)
tb1$date = as.yearmon( row.names(tb1),  "%m/%Y")
ggplot( tb1, aes(x=date, y=USA)) + geom_point()
tb1 %>% select (USA)
tb1 %>% filter( USA > 1) %>% select (USA, China)
rm( list=ls()) #clean up worksapce
library(tidyverse)
library(lubridate)
library(readxl)
tb = read_excel('gisaid_monthly_submissions_global_2021-05-12-0958.xlsx')
rm( list=ls()) #clean up worksapce
library(tidyverse)
library(lubridate)
library(readxl)
tb = read_excel('gisaid_monthly_submissions_global_2021-05-12-0958.xlsx')
?str
help(str);
head(tb)
#indexing features of R
tb[1:5, 2:3]
tb$age #what does mean?
#tb$age[?] #try for 5th row in age
# what is the 5th and 9th rows in age and SciLitScore:
tb[c(5,9), c(7,2)]
tb[c(5,9), c( '01/2020', "08/2020")]
head(tb)
head( tb[, 2:3], n=2)
### Indexing an element in a dataframe
```{r indexing}
#indexing features of R
tb[1:5, 2:3]
tb$age #what does mean?
# what is the 5th and 9th rows in age and SciLitScore:
tb[c(5,9), c(7,2)]
# what is the 5th and 9th rows in age and SciLitScore:
tb[c(5,9), c(7,2)]
```{r indexing-by-c}
tb[c(5,9), c( '01/2020', "08/2020")]
tb[c(5,9), c( '01/2020', "08/2020")]
```{r look-at-data}
head(tb)
head(tb)
Look at first 2 rows of columns 2 and 3
```{r}
head( tb[, 2:3], n=2)
```
```{r}
# how many columns?
length(tb[1,])
print(paste( "There are ", length(tb[1,]), " columns"))
# how many columns?
length(tb[1,])
print(paste( "There are ", length(tb[1,]), " columns"))
Take only the values
```{r}
tb1 = t(tb[, 2: length(tb[1,])])
tb1 = data.frame(tb1)
names(tb1) = t(tb[,1])
tail(tb1)
```
```{r}
library(zoo)
tb1$date = as.yearmon( row.names(tb1),  "%m/%Y")
library(zoo)
tb1$date = as.yearmon( row.names(tb1),  "%m/%Y")
ggplot( tb1, aes(x=date, y=USA)) + geom_point()
tb1 %>% select (USA)
tb1 %>% select (USA)
tb1 %>% filter( USA > 1) %>% select (USA, China)
head(tb1)
rm( list=ls()) #clean up worksapce
library(tidyverse)
library(lubridate)
library(readxl)
tb = read_excel('gisaid_monthly_submissions_global_2021-05-12-0958.xlsx')
?str
help(str);
head(tb)
#indexing features of R
tb[1:5, 2:3]
tb$age #what does mean?
#tb$age[?] #try for 5th row in age
# what is the 5th and 9th rows in age and SciLitScore:
tb[c(5,9), c(7,2)]
tb[c(5,9), c( '01/2020', "08/2020")]
head(tb)
head( tb[, 2:3], n=2)
# how many columns?
length(tb[1,])
print(paste( "There are ", length(tb[1,]), " columns"))
tb1 = t(tb[, 2: length(tb[1,])])
tb1 = data.frame(tb1)
names(tb1) = t(tb[,1])
tail(tb1)
library(zoo)
tb1$date = as.yearmon( row.names(tb1),  "%m/%Y")
ggplot( tb1, aes(x=date, y=USA)) + geom_point()
tb1 %>% select (USA)
tb1 %>% filter( USA > 1) %>% select (USA, China)
head(tb1)
rm( list=ls()) #clean up worksapce
library(tidyverse)
library(lubridate)
library(reshape2)
library(ggplot2)
library(dplyr)
rm( list=ls()) #clean up worksapce
library(tidyverse)
library(lubridate)
library(reshape2)
library(ggplot2)
library(dplyr)
rm( list=ls()) #clean up worksapce
library(tidyverse)
library(lubridate)
library(reshape2)
library(ggplot2)
library(dplyr)
# load JHU covid19 data set with tidyverse read_csv
# this is the URL for "view raw " for csv files on GitHub
tb = read_csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv")
?str
help(str);
str(tb[ , 1:10]);
#indexing features of R
tb[1:5, 2:3]
tb$age #what does mean?
#tb$age[?] #try for 5th row in age
# what is the 5th and 9th rows in age and SciLitScore:
tb[c(5,9), c(7,2)]
tb[c(5,9), c('FIPS', 'Admin2', "Province_State")]
head(tb)
# how many columns?
length(tb[1,])
print(paste( "There are ", length(tb[1,]), " columns"))
#tb %>% select( 12:length(tb[1,]) )
tb1 <- tb %>% dplyr::select(12:length(tb[1,])) %>% as.matrix()
tb1 = as.data.frame(t(tb1)) # t for transpose, then convert to a dataframe
tail(tb1)
names(tb1) = tb$Combined_Key
#tail(tb1[100:110,1:10])
tail(tb1[,1:10])
library(lubridate)
mdy("10/1/2020")
current_dates = names(tb)[12:length(tb[1,])]
class(current_dates)
current_dates
rm( list=ls()) #clean up worksapce
library(tidyverse)
library(lubridate)
library(reshape2)
library(ggplot2)
library(dplyr)
# load JHU covid19 data set with tidyverse read_csv
# this is the URL for "view raw " for csv files on GitHub
tb = read_csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv")
?str
help(str);
str(tb[ , 1:10]);
#indexing features of R
tb[1:5, 2:3]
tb$age #what does mean?
#tb$age[?] #try for 5th row in age
# what is the 5th and 9th rows in age and SciLitScore:
tb[c(5,9), c(7,2)]
tb[c(5,9), c('FIPS', 'Admin2', "Province_State")]
head(tb)
head( tb[, 2:3], n=2)
# how many columns?
length(tb[1,])
print(paste( "There are ", length(tb[1,]), " columns"))
#tb %>% select( 12:length(tb[1,]) )
tb1 <- tb %>% dplyr::select(12:length(tb[1,])) %>% as.matrix()
tb1 = as.data.frame(t(tb1)) # t for transpose, then convert to a dataframe
tail(tb1)
names(tb1) = tb$Combined_Key
#tail(tb1[100:110,1:10])
tail(tb1[,1:10])
library(lubridate)
mdy("10/1/2020")
current_dates = names(tb)[12:length(tb[1,])]
class(current_dates)
current_dates
mdy(current_dates[1:10])
tb1$dates = mdy(current_dates)
tail(tb1)
## Select a time window (row window) using 'filter'
tb1 %>% filter( dates > mdy("3/30/2020"), dates < mdy("5/16/20")) %>% head()
start = mdy("12/15/20")
end = start + ddays(30)
tb1 %>% dplyr::filter( dates >= start, dates <=  end)  %>% dplyr::select(1:5)
tb_sub <-
tb1 %>% dplyr::filter( dates >= start, dates <  start + ddays(30)) %>% dplyr::select( c(1:5), dates)
head(tb_sub)
ggplot(tb_sub, aes( x = dates, y=tb_sub[,3])) + geom_point() + geom_smooth()
mycounties = c( 'Montgomery, Alabama, US') #Change here to your home county and state
#mycounties = c( 'San Francisco, California, US') #Change here to your home county and state
#mycounties = c( 'Santa Clara, California, US') #Change here to your home county and state
#mycounties = c('Hennepin, Minnesota, US') #Minneapolis
#mycounties = c('Harris, Texas, US') #Houston
#mycounties = c('Cobb, Georgia, US') #Houston
#mycounties = c( 'Hamilton, Tennessee, US') #Change here to your home county and state
tb = read_csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv")
tb1 <- tb %>% dplyr::select(12:length(tb[1,])) %>% as.matrix()
tb1 = as.data.frame(t(tb1))
names(tb1) = tb$Combined_Key
current_dates = names(tb)[12:length(tb[1,])]
tb1$dates = mdy(current_dates)
#head(tb1)
days_window = 340  # time  window
endday = today(tzone ='EST')
tb_sub <- tb1 %>%
dplyr::select( all_of(mycounties), 'dates') %>%
dplyr::filter( between(dates, endday-ddays(days_window), endday))
head(tb_sub)
tb_sub[,1]
diff( tb_sub[,1])
local_dailycases = c(0, diff( tb_sub[,1] )) # we add zero to the first day
tb_daily_sub = data.frame( local_dailycases )
head(tb_daily_sub)
tb_daily_sub$YMD = mdy(row.names(tb_sub))
head(tb_daily_sub)
row.names(tb_daily_sub) = tb_daily_sub$YMD #add row names
tail(tb_daily_sub )
names(tb_daily_sub)[1] = mycounties #add column names
tail(tb_daily_sub)
myplot <- ggplot(tb_daily_sub, aes(x=YMD, y=tb_daily_sub[,1]))
myplot + geom_point() + stat_smooth(span=0.3)
# Download the Google Mobility data
url =  "https://www.gstatic.com/covid19/mobility/Region_Mobility_Report_CSVs.zip"
# download.file( url, destfile = "download/google.zip") #do not need this because google report are on Github.
# You would need to unzip the downloaded zip file
# If you use RStudio-Cloud, these file may be in your workspace
tbGMUS20 = read_csv("download/google/2020_US_Region_Mobility_Report.csv")
tail(tbGMUS20)
tbGMUS21 = read_csv("download/google/2021_US_Region_Mobility_Report.csv")
tail(tbGMUS21)
tbGMUS = rbind( tbGMUS20, tbGMUS21)
myState = 'Alabama'
myCounty = "Montgomery County" #Google location is different from JHU
tbGMmycounty <-
tbGMUS %>% filter( sub_region_1 == myState, sub_region_2 == myCounty)
head(tbGMmycounty)
max(tbGMmycounty$date) #the most recent date of the mobility report
head( tb_daily_sub)
tb_daily_mycounty = tb_daily_sub
names(tb_daily_mycounty) = c("DailyCases", "date")
tail(tb_daily_mycounty)
tb_GMCovidmycounty = merge(x=tb_daily_mycounty, y=tbGMmycounty, by= 'date', all.y=FALSE)
row.names(  tb_GMCovidmycounty ) =  tb_GMCovidmycounty$date
tail( tb_GMCovidmycounty )
names(tb_GMCovidmycounty  )
#names(tb_GMCovidmycounty  )[10:12]
print( paste( "There are ", length(tb_GMCovidmycounty[1,]), "columns"))
tb_GMCovidmycounty2  <- tb_GMCovidmycounty  %>% dplyr::select(2, 11:16 ) # select values columns
tail(tb_GMCovidmycounty2 )
tb_GMCovidmycounty_scaled <-  data.frame( scale(tb_GMCovidmycounty2) )
head( tb_GMCovidmycounty_scaled  )
# add the date column back
tb_GMCovidmycounty_scaled$date = ymd(row.names(tb_GMCovidmycounty_scaled))
tail( tb_GMCovidmycounty_scaled  )
names( tb_GMCovidmycounty_scaled )
selected_columns = c('DailyCases', "transit_stations_percent_change_from_baseline", 'workplaces_percent_change_from_baseline')
df_melt <- melt( tb_GMCovidmycounty_scaled, measure.vars=selected_columns, value.names="Values", varialbe.name="varialbe" )
plot <- ggplot(df_melt, aes(x=date, y=value, color=variable)) + stat_smooth(span=0.15)
plot + ggtitle( paste( myCounty, myState))
tb = read_csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv")
rm( list=ls()) #clean up worksapce
library(tidyverse)
library(lubridate)
library(reshape2)
library(ggplot2)
library(dplyr)
# load JHU covid19 data set with tidyverse read_csv
# this is the URL for "view raw " for csv files on GitHub
tb = read_csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv")
?str
help(str);
str(tb[ , 1:10]);
#indexing features of R
tb[1:5, 2:3]
tb$age #what does mean?
#tb$age[?] #try for 5th row in age
# what is the 5th and 9th rows in age and SciLitScore:
tb[c(5,9), c(7,2)]
tb[c(5,9), c('FIPS', 'Admin2', "Province_State")]
head(tb)
head( tb[, 2:3], n=2)
# how many columns?
length(tb[1,])
print(paste( "There are ", length(tb[1,]), " columns"))
#tb %>% select( 12:length(tb[1,]) )
tb1 <- tb %>% dplyr::select(12:length(tb[1,])) %>% as.matrix()
tb1 = as.data.frame(t(tb1)) # t for transpose, then convert to a dataframe
tail(tb1)
names(tb1) = tb$Combined_Key
#tail(tb1[100:110,1:10])
tail(tb1[,1:10])
library(lubridate)
mdy("10/1/2020")
current_dates = names(tb)[12:length(tb[1,])]
class(current_dates)
current_dates
mdy(current_dates[1:10])
tb1$dates = mdy(current_dates)
tail(tb1)
## Select a time window (row window) using 'filter'
tb1 %>% filter( dates > mdy("3/30/2020"), dates < mdy("5/16/20")) %>% head()
start = mdy("12/15/20")
end = start + ddays(30)
tb1 %>% dplyr::filter( dates >= start, dates <=  end)  %>% dplyr::select(1:5)
tb_sub <-
tb1 %>% dplyr::filter( dates >= start, dates <  start + ddays(30)) %>% dplyr::select( c(1:5), dates)
head(tb_sub)
ggplot(tb_sub, aes( x = dates, y=tb_sub[,3])) + geom_point() + geom_smooth()
mycounties = c( 'Montgomery, Alabama, US') #Change here to your home county and state
#mycounties = c( 'San Francisco, California, US') #Change here to your home county and state
#mycounties = c( 'Santa Clara, California, US') #Change here to your home county and state
#mycounties = c('Hennepin, Minnesota, US') #Minneapolis
#mycounties = c('Harris, Texas, US') #Houston
#mycounties = c('Cobb, Georgia, US') #Houston
#mycounties = c( 'Hamilton, Tennessee, US') #Change here to your home county and state
tb = read_csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv")
tb1 <- tb %>% dplyr::select(12:length(tb[1,])) %>% as.matrix()
tb1 = as.data.frame(t(tb1))
names(tb1) = tb$Combined_Key
current_dates = names(tb)[12:length(tb[1,])]
tb1$dates = mdy(current_dates)
#head(tb1)
days_window = 340  # time  window
endday = today(tzone ='EST')
tb_sub <- tb1 %>%
dplyr::select( all_of(mycounties), 'dates') %>%
dplyr::filter( between(dates, endday-ddays(days_window), endday))
tail(tb_sub)
tb_sub[,1]
tb = read_csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv")
tb1 <- tb %>% dplyr::select(12:length(tb[1,])) %>% as.matrix()
tb1 = as.data.frame(t(tb1))
names(tb1) = tb$Combined_Key
current_dates = names(tb)[12:length(tb[1,])]
tb1$dates = mdy(current_dates)
#head(tb1)
days_window = 600  # time  window
endday = today(tzone ='EST')
tb_sub <- tb1 %>%
dplyr::select( all_of(mycounties), 'dates') %>%
dplyr::filter( between(dates, endday-ddays(days_window), endday))
tail(tb_sub)
tb_sub[,1]
diff( tb_sub[,1])
local_dailycases = c(0, diff( tb_sub[,1] )) # we add zero to the first day
tb_daily_sub = data.frame( local_dailycases )
head(tb_daily_sub)
tb_daily_sub$YMD = mdy(row.names(tb_sub))
head(tb_daily_sub)
row.names(tb_daily_sub) = tb_daily_sub$YMD #add row names
tail(tb_daily_sub )
# Download the Google Mobility data
url =  "https://www.gstatic.com/covid19/mobility/Region_Mobility_Report_CSVs.zip"
# download.file( url, destfile = "download/google.zip") #do not need this because google report are on Github.
# You would need to unzip the downloaded zip file
tbGMUS22 = read_csv("download/google/2022_US_Region_Mobility_Report.csv")
tbGMUS22 = read_csv("download/google/2022_US_Region_Mobility_Report.csv")
tail(tbGMUS22)
tbGMUS = rbind( tbGMUS20, tbGMUS21, tbGMUSD22)
# If you use RStudio-Cloud, these file may be in your workspace
tbGMUS20 = read_csv("download/google/2020_US_Region_Mobility_Report.csv")
tail(tbGMUS20)
tbGMUS = rbind( tbGMUS20, tbGMUS21, tbGMUSD22)
myState = 'Alabama'
myCounty = "Montgomery County" #Google location is different from JHU
tbGMmycounty <-
tbGMUS %>% filter( sub_region_1 == myState, sub_region_2 == myCounty)
tbGMUS21 = read_csv("download/google/2021_US_Region_Mobility_Report.csv")
tail(tbGMUS21)
tbGMUS22 = read_csv("download/google/2022_US_Region_Mobility_Report.csv")
tail(tbGMUS22)
tbGMUS = rbind( tbGMUS20, tbGMUS21, tbGMUSD22)
tbGMUS = rbind( tbGMUS20, tbGMUS21, tbGMUS22)
myState = 'Alabama'
myCounty = "Montgomery County" #Google location is different from JHU
tbGMmycounty <-
tbGMUS %>% filter( sub_region_1 == myState, sub_region_2 == myCounty)
head(tbGMmycounty)
